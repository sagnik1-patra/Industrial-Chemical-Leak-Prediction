{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39252570-b2b9-4a5c-9338-6be79dcb7eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NXTWAVE\\AppData\\Local\\Temp\\ipykernel_16556\\1424375690.py:26: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1 = pd.read_csv(FILE1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded datasets successfully!\n",
      "Merged dataset shape: (3513028, 18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NXTWAVE\\AppData\\Local\\Temp\\ipykernel_16556\\1424375690.py:53: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = df.fillna(method=\"ffill\").fillna(method=\"bfill\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/40\n",
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "68100/68100 [==============================] - 147s 2ms/step - loss: 7.2129e-04 - mae: 0.0158 - val_loss: 6.3843e-04 - val_mae: 0.0146\n",
      "Epoch 2/40\n",
      "68100/68100 [==============================] - 161s 2ms/step - loss: 6.7404e-04 - mae: 0.0152 - val_loss: 6.3212e-04 - val_mae: 0.0151\n",
      "Epoch 3/40\n",
      "68100/68100 [==============================] - 160s 2ms/step - loss: 6.5815e-04 - mae: 0.0149 - val_loss: 6.1813e-04 - val_mae: 0.0138\n",
      "Epoch 4/40\n",
      "68100/68100 [==============================] - 159s 2ms/step - loss: 6.5101e-04 - mae: 0.0148 - val_loss: 6.0198e-04 - val_mae: 0.0145\n",
      "Epoch 5/40\n",
      "68100/68100 [==============================] - 157s 2ms/step - loss: 6.4850e-04 - mae: 0.0148 - val_loss: 6.1292e-04 - val_mae: 0.0147\n",
      "Epoch 6/40\n",
      "68100/68100 [==============================] - 145s 2ms/step - loss: 6.4422e-04 - mae: 0.0147 - val_loss: 6.0776e-04 - val_mae: 0.0141\n",
      "Epoch 7/40\n",
      "68100/68100 [==============================] - 130s 2ms/step - loss: 6.4090e-04 - mae: 0.0147 - val_loss: 6.1274e-04 - val_mae: 0.0142\n",
      "Epoch 8/40\n",
      "68100/68100 [==============================] - 129s 2ms/step - loss: 6.4121e-04 - mae: 0.0147 - val_loss: 6.1837e-04 - val_mae: 0.0137\n",
      "Epoch 9/40\n",
      "68100/68100 [==============================] - 3658s 54ms/step - loss: 6.3803e-04 - mae: 0.0146 - val_loss: 5.9642e-04 - val_mae: 0.0140\n",
      "Epoch 10/40\n",
      "68100/68100 [==============================] - 4591s 67ms/step - loss: 6.3619e-04 - mae: 0.0146 - val_loss: 6.0429e-04 - val_mae: 0.0136\n",
      "Epoch 11/40\n",
      "68100/68100 [==============================] - 128s 2ms/step - loss: 6.3265e-04 - mae: 0.0146 - val_loss: 5.9083e-04 - val_mae: 0.0134\n",
      "Epoch 12/40\n",
      "68100/68100 [==============================] - 135s 2ms/step - loss: 6.3231e-04 - mae: 0.0146 - val_loss: 6.0180e-04 - val_mae: 0.0137\n",
      "Epoch 13/40\n",
      "68100/68100 [==============================] - 132s 2ms/step - loss: 6.3183e-04 - mae: 0.0146 - val_loss: 5.9610e-04 - val_mae: 0.0140\n",
      "Epoch 14/40\n",
      "68100/68100 [==============================] - 136s 2ms/step - loss: 6.3073e-04 - mae: 0.0146 - val_loss: 6.0146e-04 - val_mae: 0.0144\n",
      "Epoch 15/40\n",
      "68100/68100 [==============================] - 135s 2ms/step - loss: 6.3001e-04 - mae: 0.0146 - val_loss: 6.0614e-04 - val_mae: 0.0134\n",
      "Epoch 16/40\n",
      "68100/68100 [==============================] - 134s 2ms/step - loss: 6.2853e-04 - mae: 0.0146 - val_loss: 5.9415e-04 - val_mae: 0.0140\n",
      "‚ö† YAML export deprecated in new TensorFlow, JSON saved instead.\n",
      "\n",
      "============================================\n",
      "üéâ ALL FILES SAVED SUCCESSFULLY!\n",
      "üìÅ Location: C:\\Users\\NXTWAVE\\Downloads\\Industrial Chemical Leak Prediction\n",
      "============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# ==========================================================\n",
    "# üìå PATHS\n",
    "# ==========================================================\n",
    "BASE = r\"C:\\Users\\NXTWAVE\\Downloads\\Industrial Chemical Leak Prediction\"\n",
    "\n",
    "FILE1 = os.path.join(BASE, r\"archive\\station_hour.csv\")\n",
    "FILE2 = os.path.join(BASE, r\"archive\\stations.csv\")\n",
    "FILE3 = os.path.join(BASE, r\"archive\\city_hour.csv\")\n",
    "FILE4 = os.path.join(BASE, r\"archive\\station_day.csv\")\n",
    "FILE5 = os.path.join(BASE, r\"archive\\station_day.csv\")  # duplicate as requested\n",
    "\n",
    "# ==========================================================\n",
    "# üìå LOAD ALL DATA\n",
    "# ==========================================================\n",
    "df1 = pd.read_csv(FILE1)\n",
    "df2 = pd.read_csv(FILE2)\n",
    "df3 = pd.read_csv(FILE3)\n",
    "df4 = pd.read_csv(FILE4)\n",
    "df5 = pd.read_csv(FILE5)\n",
    "\n",
    "print(\"Loaded datasets successfully!\")\n",
    "\n",
    "# ==========================================================\n",
    "# üìå MERGE INTO ONE DATAFRAME\n",
    "# ==========================================================\n",
    "# Reset index and concatenate safely\n",
    "df = pd.concat([df1, df3, df4, df5], ignore_index=True)\n",
    "\n",
    "# Merge station metadata if \"station\" column exists\n",
    "if \"station\" in df.columns and \"station\" in df2.columns:\n",
    "    df = df.merge(df2, on=\"station\", how=\"left\")\n",
    "\n",
    "print(\"Merged dataset shape:\", df.shape)\n",
    "\n",
    "# ==========================================================\n",
    "# üìå CLEANING\n",
    "# ==========================================================\n",
    "# Remove duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Fill missing numeric values\n",
    "df = df.fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
    "\n",
    "# Keep numeric columns only\n",
    "df_numeric = df.select_dtypes(include=[np.number])\n",
    "\n",
    "if df_numeric.shape[1] < 2:\n",
    "    raise ValueError(\"Not enough numeric columns to train the model!\")\n",
    "\n",
    "# ==========================================================\n",
    "# üìå FEATURE‚ÄìTARGET SPLIT\n",
    "# ==========================================================\n",
    "# Last numeric column = target (Industry Waste Index)\n",
    "X = df_numeric.iloc[:, :-1].values\n",
    "y = df_numeric.iloc[:, -1].values\n",
    "\n",
    "# Scale X and y\n",
    "scaler_X = MinMaxScaler()\n",
    "X = scaler_X.fit_transform(X)\n",
    "\n",
    "scaler_y = MinMaxScaler()\n",
    "y = scaler_y.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# ==========================================================\n",
    "# üìå BUILD MODEL\n",
    "# ==========================================================\n",
    "model = Sequential([\n",
    "    Dense(128, activation=\"relu\", input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation=\"relu\"),\n",
    "    Dense(1, activation=\"linear\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "\n",
    "# ==========================================================\n",
    "# üìå TRAIN MODEL\n",
    "# ==========================================================\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=40,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ==========================================================\n",
    "# üìå SAVE OUTPUT FILES\n",
    "# ==========================================================\n",
    "\n",
    "SAVE_PATH = BASE\n",
    "\n",
    "# 1Ô∏è‚É£ H5 file\n",
    "model.save(os.path.join(SAVE_PATH, \"industry_waste_model.h5\"))\n",
    "\n",
    "# 2Ô∏è‚É£ PKL file (scalers + model weights)\n",
    "with open(os.path.join(SAVE_PATH, \"industry_waste_model.pkl\"), \"wb\") as f:\n",
    "    pickle.dump({\"scaler_X\": scaler_X, \"scaler_y\": scaler_y,\n",
    "                 \"weights\": model.get_weights()}, f)\n",
    "\n",
    "# 3Ô∏è‚É£ JSON architecture\n",
    "with open(os.path.join(SAVE_PATH, \"industry_waste_model.json\"), \"w\") as f:\n",
    "    f.write(model.to_json())\n",
    "\n",
    "# 4Ô∏è‚É£ YAML architecture\n",
    "try:\n",
    "    yaml_string = model.to_yaml()\n",
    "    with open(os.path.join(SAVE_PATH, \"industry_waste_model.yaml\"), \"w\") as f:\n",
    "        f.write(yaml_string)\n",
    "except:\n",
    "    print(\"‚ö† YAML export deprecated in new TensorFlow, JSON saved instead.\")\n",
    "\n",
    "print(\"\\n============================================\")\n",
    "print(\"üéâ ALL FILES SAVED SUCCESSFULLY!\")\n",
    "print(\"üìÅ Location:\", SAVE_PATH)\n",
    "print(\"============================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee91c79-d945-4ad8-85f1-8ea8f4659e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
